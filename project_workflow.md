# Workflow and documentation

## 06/26/2023 - 06/28/2023
- Learn version control via git/github
  -	Create github and slack accounts so you can get added to the Subramaniam labâ€™s Slack group and Github groups
  -	Learn how the command line/terminal works
  -	Install github on our computers using the command line
  -	Go over the basics of version control
- Learn Markdown
- Get familiarized with VSCode, which we will use to take notes in Markdown and eventually to code Jupyter notebooks
- Read about CRISPR technologies

## 06/29/2023
- Pull remote repo using command line to update your local computers (```git pull origin main```). In general, it's good practice to start the day with a ```git pull origin main``` just to make sure everything is up to date.

### Setting up our python coding environment
1. Follow the instructions in the [installing miniconda](https://github.com/kychen37/rasilab_spelman_2023/blob/main/README.md#installing-miniconda) section of our repo's README file
2. Open VSCode, and find the Extensions panel on the lefthand side
  - read more about VSCode [Extensions](https://code.visualstudio.com/docs/editor/extension-marketplace#:~:text=VS%20Code%20extensions%20let%20you,APIs%20used%20by%20VS%20Code.)
3. Search for the extension called Jupyter and download it
4. Open our rasilab_spelman_2023 folder in VSCode, and work through the python tutorials located in the ```code``` directory (see below for details)
  - If VSCode asks you to download other extensions, go ahead and install them (e.g., I think IPykernel will be one of the extensions that's needed)

### Python tutorials
- Do the tutorials located in our ```code``` folder in order:
  1. Jupyter_and_Python_Basics.ipynb
    - In the upper right corner of each notebook, click on "Select Kernel" -> "Python Environments" -> and select "(base) miniconda3/bin/python" 
  2. python_tutorial.ipynb
      - Note: Where the notebook says **Exercise**, complete the code chunk with your own code (it may contain some code already to get you started)  
- Optional tutorials:
  1. If interested, you can delve deeper into python functions with: python_functions_intro.ipynb -> procedural_programming_in_python.ipynb

### Saving and version controlling your work
- Save your jupyter notebooks as "yourinitials_nameofnotebook.ipynb" (e.g., "kc_Jupyter_and_Python_Basics.ipynb") and then push them to github
  - If you both work off the same notebook without changing the names, and both try to push that notebook to our github repo, you will probably get something called merge conflicts (i.e. two contributors changing the same lines of the same file), which are resolvable but this way we avoid them entirely
- In general and going forward, if you want to make your own files (either to take your own notes or to play around with python in jupyter notebooks), just make sure to follow our current directory structure, for example:
  - Any note-taking files should be written in markdown and saved as "yourinitials_descriptive_name_of_your_choice.md" into the ```notes``` folder
  - Any jupyter notebooks should be saved as "yourinitials_descriptive_name_of_your_choice.ipynb" into the ```code``` folder
  - Version control these files by pushing them to github periodically and practice writing descriptiive commit messages (a good commit message succinctly descibes what you changed to the file compared to your last commit)

## ReLiC screening GO analysis
- Read CiBerseq paper: https://www.science.org/doi/10.1126/science.abb9662
  - This is not exactly the same as our ReLiC screens (note that this screen is in yeast cells, ours is in human cells, among other differences) but the concepts are very similar
  - Take notes in markdown and save either in your current notes file under a new heading, or as a new markdown file following our current directory/naming structure (described in the section above)
- We will go through the ReLiC (stands for _RNA_-_linked_ _CRISPR_ screening) screening presentation together, which describes the experimental approaches that generated the data you will be working with.
- After the presentation, start a python jupyter notebook and read in one of the "mageck" datasets located in the ```data``` folder (gq for Grace and cb for Christine) using ```pandas``` in python
  - These datasets are both "gene summaries" that were generated using the software called [MAGeCK](https://sourceforge.net/p/mageck/wiki/Home/): see [gene summary](https://sourceforge.net/p/mageck/wiki/Home/#gene_summary_txt) section of wiki
- Dataset descriptions:
  - cb_mageck.gene_summary.tsv is the NMD ReLiC results
    - generated by running ```mageck test``` using PTC barcode counts ("treatment") against mCherry barcode counts ("control")
  - gq_mageck.gene_summary.tsv is the splicing ReLiC results
    - generated by running ```mageck test``` using intron-retained barcode counts ("treatment") against mCherry barcode counts ("control")
- Play around with the datasets in ```pandas``` and see if you can make sense of the column names ([MAGeCK](https://sourceforge.net/p/mageck/wiki/Home/) will be very useful for this) and what the data is conveying
  - Note that the ```id``` collumn in each dataset refers to the sgRNA, and sgRNAs (in combo with Cas9) knock out the genes they target.
- Read/research about what a GO (Gene Ontology) analysis is, particularly in the context of CRISPR screens
- Figure out how to input your data in the appropriate order/format into this website: https://cbl-gorilla.cs.technion.ac.il/
- Figure out what the outputs mean
- Summarize your findings in one final-ish document that we can send to Rasi, this document should contain:
  - What you did to the dataset (you can describe this in words, code, or pseudocode) before feeding it into the GO website
  - What the results/outputs were from the GO website
  - Your interpretation of the outputs from the GO website in the context of the ReLiC screen you're working with

## Visualizing GO analysis output
- With your RELIC screen GO analysis outputs (the csv files called ```cb_go_output.csv``` and ```gq_go_output.csv``` inside our ```data``` directory), you will want to do the following using ```pandas``` in a python jupyter notebook:
  - Filter your dataframe so that you only keep data where q < 0.05.
  - Figure out how to split the column named "Enrichment (N, B, n, b)" such that you just keep the information in front of the parenthesis 
    - For example, if the cell's value is "4.48 (2150,115,263,63)", we just want to keep the "4.48" value since the values inside the parenthesis are not useful to us at the moment
    - This is harder than it seems! I recommend thinking about what you want to do to the dataframe in words, and googling that along with the keywords "python" and "pandas". StackOverflow is a useful website where people frequently ask code-related questions and get good answers.
  - Finally, plot a histogram of enrichment values from the resultant data. This will help us decide where to cut off the data such that we aren't needing to make a plot out of a ton of terms.
- The jupyter notebook ```code/kc_pandas_go_analysis.ipynb``` will probably help you get started (treat it as a ```pandas``` tutorial). You should save this notebook into our ```code``` directory with your initials, and then you can do your analysis there if you like. Either way, make sure to version control your code (.ipynb files) and notes (.md files) and name your files following the conventions noted above that we talked about previously.

## Make a final table of GO terms for the splicing screen
- As Rasi said in this [comment](https://github.com/kychen37/rasilab_spelman_2023/issues/1#issuecomment-1642887767), the results of the GO analysis for the splicing screen are straight-forward enough that we can just present it as a table
- In a jupyter notebook (can use the one you used before or make a new one) using ```pandas```:
  - Select the columns containing information for GO term, description, q-value, enrichment, and number of genes in that GO term
    - Remember that the "Enrichment (N, B, n, b)" column is defined as:
      - N - is the total number of genes
      - B - is the total number of genes associated with a specific GO term
      - n - is the number of genes in the top of the user's input list or in the target set when appropriate
      - b - is the number of genes in the intersection
      - Enrichment = (b/n) / (B/N)
    - That means we will want to split the "Enrichment (N, B, n, b)" column and keep just the information for "Enrichment" and "B"
  - Once you've done the above, sort by ascending q-value (aka the lowest/most significant q-values are at the top)
  - Filter q < 0.05
  - Save as a csv file into the "data" directory and name it "gq_splicing_go_table.csv"
- (we will see once we finish analyzing our GO outputs for the NMD screen what is the best way to present that data)

## Weeks 5 and 6
### Make a final table of GO terms for the NMD screen
- Following our discussion on our [issues board](https://github.com/kychen37/rasilab_spelman_2023/issues/1), we've decided that our next goal is to repeat the analysis above for the NMD screen results
- For the NMD data ("data/cb_go_output.csv"), use a python jupyter notebook and ```pandas``` to:
  - Select the columns containing information for GO term, description, q-value, enrichment, and number of genes in that GO term
    - Remember that the "Enrichment (N, B, n, b)" column is defined as:
      - N - is the total number of genes
      - B - is the total number of genes associated with a specific GO term
      - n - is the number of genes in the top of the user's input list or in the target set when appropriate
      - b - is the number of genes in the intersection
      - Enrichment = (b/n) / (B/N)
    - That means we will want to split the "Enrichment (N, B, n, b)" column and keep just the information for "Enrichment" and "B"
  - Once you've done the above, sort by ascending q-value (aka the lowest/most significant q-values are at the top)
  - Filter q < 0.05 (anything above 0.05 is not considered significant by convention)
  - Save as a csv file into the "data" directory and name it "cb_nmd_go_table.csv"

### Documentation!
- Proper documentation is super important for reproducibility. It helps other labs/groups reproduce our work, and it helps us remember what was done many months in the future when it's finally time to put a paper together.
- Please reorganize your files within our github repo to follow the directory conventions as follows:
  - any jupyter notebooks should be in the "code" directory
  - any notes (in markdown format) should be in the "notes" directory
  - any data you generated should be saved as a ```csv``` file and in the "data" directory
- If you need to move files around that you have already version controlled (aka you've already ```git pushed``` these files in the past), then you will want to do a ```git mv``` on them. This will ensure that they remain version controlled even when you move them to a new location.
  - For example, I can see that the jupyter notebook named "gq_filtered_df_2.ipynb" is version controlled and currently in the "data" directory, but should be in the "code" directory
  - To move it with ```git```, you would run: ```git mv data/gq_filtered_df_2.ipynb code/gq_filtered_df_2.ipynb``` (the pattern is basically "git mv" "current location" "new location")
  - Then, if you run ```git status``` to see what has been done, you should see that this move has been staged, so you can just ```git commit``` and ```push``` as usual
  - Do this for any remaining files that need to be reorganized
- Once you have reorganized any files that need to be moved around, please go back in to any jupyter notebooks that got moved and make sure all the code still runs as expected. Fix any bugs that may now occur due to the file location change.
- Once all the reorganizing is done (seems trivial, but can take a good chunk of time and troubleshooting!), please add a section in your summary document with the header "Documentation", which states the **filename and location** (aka what directory it's in) of:
  - The CRISPR data you were given
  - The output (csv file) of the GO analysis (before you did anything to it)
  - The final GO analysis table
  - The code (jupyter notebook) that generated that final table
- Just a reminder of the other things your summary file should include:
  - What you did to the dataset (you can describe this in words, code, or pseudocode) before feeding it into the GO website (please also link the GO website we used)
  - What the results/outputs were from the GO website: a screenshot of the diagrams would be helpful here
  - Your interpretation of the outputs from the GO website in the context of the ReLiC screen you're working with
- Reminder to please write this summary document in markdown so it can be easily pushed to our github repo and referred to in the future
  - To insert the screenshot image of your GO output diagrams into the markdown file, use this code in your markdown document: ```<img src="path_to_image_file", width=500px>```
  - The "width" is in pixels describes how large to make the image (you can adjust it larger or smaller)
  - The screenshotted image should be renamed to be something easily computer-readable (e.g. "splicing_go_output_dag.png" or something similar)
  - The image should also be pushed to github
  - When you look at your summary document on github (i.e. on the [web]("https://github.com/kychen37/rasilab_spelman_2023/tree/main")), you should see the image you linked displayed within the file. If you don't see it, that means you need to fix the link by changing the path in your markdown document
- Finally, if you have time to convert the notes you have on google docs to markdown and push them to github that would be ideal. Currently it doesn't look like I have access to the google doc that you linked on our [README](https://github.com/kychen37/rasilab_spelman_2023/blob/main/README.md#link-to-notes-checklist) page

### Presentations
- Whenever you finish the above, you can work on the presentations you have coming up:
  - We are scheduled to have one more Short Updates lab meeting on Aug 2nd (prepare 2-3 slides each about your experience and your exciting analysis results!)
  - Your research posters for Spelman College