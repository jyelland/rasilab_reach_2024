# Workflow and documentation

## 06/26/2023 - 06/28/2023
- Learn version control via git/github
  -	Create github and slack accounts so you can get added to the Subramaniam labâ€™s Slack group and Github groups
  -	Learn how the command line/terminal works
  -	Install github on our computers using the command line
  -	Go over the basics of version control
- Learn Markdown
- Get familiarized with VSCode, which we will use to take notes in Markdown and eventually to code Jupyter notebooks
- Read about CRISPR technologies

## 06/29/2023
- Pull remote repo using command line to update your local computers (```git pull origin main```). In general, it's good practice to start the day with a ```git pull origin main``` just to make sure everything is up to date.

### Setting up our python coding environment
1. Follow the instructions in the [installing miniconda](https://github.com/kychen37/rasilab_spelman_2023/blob/main/README.md#installing-miniconda) section of our repo's README file
2. Open VSCode, and find the Extensions panel on the lefthand side
  - read more about VSCode [Extensions](https://code.visualstudio.com/docs/editor/extension-marketplace#:~:text=VS%20Code%20extensions%20let%20you,APIs%20used%20by%20VS%20Code.)
3. Search for the extension called Jupyter and download it
4. Open our rasilab_spelman_2023 folder in VSCode, and work through the python tutorials located in the ```code``` directory (see below for details)
  - If VSCode asks you to download other extensions, go ahead and install them (e.g., I think IPykernel will be one of the extensions that's needed)

### Python tutorials
- Do the tutorials located in our ```code``` folder in order:
  1. Jupyter_and_Python_Basics.ipynb
    - In the upper right corner of each notebook, click on "Select Kernel" -> "Python Environments" -> and select "(base) miniconda3/bin/python" 
  2. python_tutorial.ipynb
      - Note: Where the notebook says **Exercise**, complete the code chunk with your own code (it may contain some code already to get you started)  
- Optional tutorials:
  1. If interested, you can delve deeper into python functions with: python_functions_intro.ipynb -> procedural_programming_in_python.ipynb

### Saving and version controlling your work
- Save your jupyter notebooks as "yourinitials_nameofnotebook.ipynb" (e.g., "kc_Jupyter_and_Python_Basics.ipynb") and then push them to github
  - If you both work off the same notebook without changing the names, and both try to push that notebook to our github repo, you will probably get something called merge conflicts (i.e. two contributors changing the same lines of the same file), which are resolvable but this way we avoid them entirely
- In general and going forward, if you want to make your own files (either to take your own notes or to play around with python in jupyter notebooks), just make sure to follow our current directory structure, for example:
  - Any note-taking files should be written in markdown and saved as "yourinitials_descriptive_name_of_your_choice.md" into the ```notes``` folder
  - Any jupyter notebooks should be saved as "yourinitials_descriptive_name_of_your_choice.ipynb" into the ```code``` folder
  - Version control these files by pushing them to github periodically and practice writing descriptiive commit messages (a good commit message succinctly descibes what you changed to the file compared to your last commit)

## ReLiC screening GO analysis
- Read CiBerseq paper: https://www.science.org/doi/10.1126/science.abb9662
  - This is not exactly the same as our ReLiC screens (note that this screen is in yeast cells, ours is in human cells, among other differences) but the concepts are very similar
  - Take notes in markdown and save either in your current notes file under a new heading, or as a new markdown file following our current directory/naming structure (described in the section above)
- We will go through the ReLiC (stands for _RNA_-_linked_ _CRISPR_ screening) screening presentation together, which describes the experimental approaches that generated the data you will be working with.
- After the presentation, start a python jupyter notebook and read in one of the "mageck" datasets located in the ```data``` folder (gq for Grace and cb for Christine) using ```pandas``` in python
  - These datasets are both "gene summaries" that were generated using the software called [MAGeCK](https://sourceforge.net/p/mageck/wiki/Home/): see [gene summary](https://sourceforge.net/p/mageck/wiki/Home/#gene_summary_txt) section of wiki
- Dataset descriptions:
  - cb_mageck.gene_summary.tsv is the NMD ReLiC results
    - generated by running ```mageck test``` using PTC barcode counts ("treatment") against mCherry barcode counts ("control")
  - gq_mageck.gene_summary.tsv is the splicing ReLiC results
    - generated by running ```mageck test``` using intron-retained barcode counts ("treatment") against mCherry barcode counts ("control")
- Play around with the datasets in ```pandas``` and see if you can make sense of the column names ([MAGeCK](https://sourceforge.net/p/mageck/wiki/Home/) will be very useful for this) and what the data is conveying
  - Note that the ```id``` collumn in each dataset refers to the sgRNA, and sgRNAs (in combo with Cas9) knock out the genes they target.
- Read/research about what a GO (Gene Ontology) analysis is, particularly in the context of CRISPR screens
- Figure out how to input your data in the appropriate order/format into this website: https://cbl-gorilla.cs.technion.ac.il/
- Figure out what the outputs mean
- Summarize your findings in one final-ish document that we can send to Rasi, this document should contain:
  - What you did to the dataset (you can describe this in words, code, or pseudocode) before feeding it into the GO website
  - What the results/outputs were from the GO website
  - Your interpretation of the outputs from the GO website in the context of the ReLiC screen you're working with

## Visualizing GO analysis output
- With your RELIC screen GO analysis outputs (the csv files called ```cb_go_output.csv``` and ```gq_go_output.csv``` inside our ```data``` directory), you will want to do the following using ```pandas``` in a python jupyter notebook:
  - Filter your dataframe so that you only keep data where q < 0.05.
  - Figure out how to split the column named "Enrichment (N, B, n, b)" such that you just keep the information in front of the parenthesis 
    - For example, if the cell's value is "4.48 (2150,115,263,63)", we just want to keep the "4.48" value since the values inside the parenthesis are not useful to us at the moment
    - This is harder than it seems! I recommend thinking about what you want to do to the dataframe in words, and googling that along with the keywords "python" and "pandas". StackOverflow is a useful website where people frequently ask code-related questions and get good answers.
  - Finally, plot a histogram of enrichment values from the resultant data. This will help us decide where to cut off the data such that we aren't needing to make a plot out of a ton of terms.
- The jupyter notebook ```code/kc_pandas_go_analysis.ipynb``` will probably help you get started (treat it as a ```pandas``` tutorial). You should save this notebook into our ```code``` directory with your initials, and then you can do your analysis there if you like. Either way, make sure to version control your code (.ipynb files) and notes (.md files) and name your files following the conventions noted above that we talked about previously.

## Make a final table of GO terms for the splicing screen
- As Rasi said in this [comment](https://github.com/kychen37/rasilab_spelman_2023/issues/1#issuecomment-1642887767), the results of the GO analysis for the splicing screen are straight-forward enough that we can just present it as a table
- In a jupyter notebook (can use the one you used before or make a new one) using ```pandas```:
  - Select the columns containing information for GO term, description, q-value, enrichment, and number of genes in that GO term
    - Remember that the "Enrichment (N, B, n, b)" column is defined as:
      - N - is the total number of genes
      - B - is the total number of genes associated with a specific GO term
      - n - is the number of genes in the top of the user's input list or in the target set when appropriate
      - b - is the number of genes in the intersection
      - Enrichment = (b/n) / (B/N)
    - That means we will want to split the "Enrichment (N, B, n, b)" column and keep just the information for "Enrichment" and "B"
  - Once you've done the above, sort by ascending q-value (aka the lowest/most significant q-values are at the top)
  - Filter q < 0.05
  - Save as a csv file into the "data" directory and name it "gq_splicing_go_table.csv"
- (we will see once we finish analyzing our GO outputs for the NMD screen what is the best way to present that data)